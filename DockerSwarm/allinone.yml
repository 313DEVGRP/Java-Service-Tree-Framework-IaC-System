version: '3.6'

#hosts ( 127.0.0.1 313.co.kr )
#docker login 313.co.kr:5550 ( admin / qwe123 )
#ln -s /nfs/DockerPV/allinone/jenkins_agent/jenkins_home_3 jenkins_home

services:

  traefik:
    image: traefik:v2.10.4
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: host
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      - "TZ=Asia/Seoul"
    networks: &allinoneNetwork
      - allinoneNetwork
    extra_hosts: &addhost
      - "313.co.kr:192.168.25.31"
      - "db.313.co.kr:192.168.25.40"
      - "nas.313.co.kr:192.168.25.42"
      - "ubuntu.313.co.kr:192.168.25.31"
      - "www.313.co.kr:192.168.25.31"
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
      labels:
        - "traefik.enable=true"
        - "traefik.http.services.traefik.loadbalancer.server.port=80"
        - "traefik.http.routers.dashboard.rule=PathPrefix(`/api`, `/dashboard`)"
        - "traefik.http.routers.dashboard.service=api@internal"
        - "traefik.http.routers.dashboard.entrypoints=web"
        - "traefik.http.routers.dashboard.middlewares=auth"
        - "traefik.http.middlewares.auth.basicauth.users=test:$$apr1$$H6uskkkW$$IgXLP6ewTrSuBkTrqE8wj/"
    command:
      - "--providers.docker"
      - "--api.dashboard=true"
      - "--api.insecure=true"
      - "--providers.docker.swarmMode=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
      - "--accesslog"
      - "--log.level=INFO"

  nginx:
    image: nginx:1.19.10
    volumes:
      - nginx-conf:/etc/nginx
      - nginx-www:/usr/share/nginx/html
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    networks: &allinoneNetwork
      - allinoneNetwork
    extra_hosts: *addhost
    depends_on:
      - keycloak
    deploy:
      mode: global
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.nginx.rule=PathPrefix(`/`)"
        - "traefik.http.routers.nginx.service=nginx"
        - "traefik.http.routers.nginx.entrypoints=web"
        #- "traefik.http.services.nginx.loadBalancer.sticky.cookie=true"
        #- "traefik.http.services.nginx.loadBalancer.sticky.cookie.name=nginx_sticky_cookie_session"
        - "traefik.http.services.nginx.loadbalancer.server.port=80"
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: nginx

  apachephp:
    image: 313.co.kr:5550/313devgrp/apachephp:3.1.3
    volumes:
      - apachephp-volume:/var/www/html
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: apachephp

  ######################################### Global Service #########################################

  agent:
    image: portainer/agent:2.11.0
      #environment:
      # REQUIRED: Should be equal to the service name prefixed by "tasks." when
      # deployed inside an overlay network
      #- "AGENT_CLUSTER_ADDR=tasks.agent"
      #- "AGENT_PORT=9001"
    #- "LOG_LEVEL=debug"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    networks: *allinoneNetwork
    extra_hosts: *addhost
    deploy:
      mode: global
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: portaineragent

  portainer:
    image: portainer/portainer-ce:2.11.0
    command: -H tcp://tasks.agent:9001 --tlsskipverify
    volumes:
      - portainer-volume:/data
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    networks: *allinoneNetwork
    extra_hosts: *addhost
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: portainer

  grafana:
    image: portainer/template-swarm-monitoring:grafana-9.5.2
    deploy:
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    volumes:
      - type: volume
        source: grafana-data
        target: /var/lib/grafana
      - type: volume
        source: grafana-etc
        target: /etc/grafana
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=qwe123
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=true
      #- GF_SECURITY_ALLOW_EMBEDDING=true
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: grafana

  prometheus:
    image: portainer/template-swarm-monitoring:prometheus-v2.44.0
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--log.level=error'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
    deploy:
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    volumes:
      - type: volume
        source: prometheus-volume
        target: /prometheus
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: prometheus

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.0
    command: -logtostderr -docker_only
    deploy:
      mode: global
    volumes:
      - type: bind
        source: /
        target: /rootfs
        read_only: true
      - type: bind
        source: /var/run
        target: /var/run
        read_only: true
      - type: bind
        source: /sys
        target: /sys
        read_only: true
      - type: bind
        source: /var/lib/docker
        target: /var/lib/docker
        read_only: true
      - type: bind
        source: /dev/disk
        target: /dev/disk
        read_only: true
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: cadvisor

  node-exporter:
    image: prom/node-exporter:v1.5.0
    command:
      - '--path.sysfs=/host/sys'
      - '--path.procfs=/host/proc'
      - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)'
      - '--no-collector.ipvs'
    deploy:
      mode: global
    volumes:
      - type: bind
        source: /
        target: /rootfs
        read_only: true
      - type: bind
        source: /proc
        target: /host/proc
        read_only: true
      - type: bind
        source: /sys
        target: /host/sys
        read_only: true
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: nodeexporter

  ######################################### ELFK #########################################

  es-master-01:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELKVERSION:-7.17.13}
    hostname: es-master-01
    volumes:
      - type: volume
        source: es-master-01
        target: /usr/share/elasticsearch/data
        volume:
          nocopy: true
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      network.host: 0.0.0.0
      cluster.name: es-swarm-cluster
      node.name: "es-master-01"
      discovery.seed_hosts: "es-master-01,es-master-02,es-master-03"
      cluster.initial_master_nodes: "es-master-01,es-master-02,es-master-03"
      node.master: "true"
      node.voting_only: "false"
      node.data: "false"
      node.ingest: "false"
      node.ml: "false"
      xpack.ml.enabled: "false"
      cluster.remote.connect: "false"
      MAX_LOCKED_MEMORY: unlimited
      bootstrap.memory_lock: "true"
      ES_JAVA_OPTS: "-Xms3g -Xmx3g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    depends_on:
      - es-data-01
      - es-data-02
    configs: &eslimitsConf
      - source: es-limits.conf
        target: /etc/security/limits.conf
    networks: *allinoneNetwork
    extra_hosts: *addhost
    deploy:
      endpoint_mode: dnsrr
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    logging: &allinoneLogging
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "100m"

  es-master-02:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELKVERSION:-7.17.13}
    hostname: es-master-02
    volumes:
      - type: volume
        source: es-master-02
        target: /usr/share/elasticsearch/data
        volume:
          nocopy: true
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      network.host: 0.0.0.0
      cluster.name: es-swarm-cluster
      node.name: "es-master-02"
      discovery.seed_hosts: "es-master-01,es-master-02,es-master-03"
      cluster.initial_master_nodes: "es-master-01,es-master-02,es-master-03"
      node.master: "true"
      node.voting_only: "false"
      node.data: "false"
      node.ingest: "false"
      node.ml: "false"
      xpack.ml.enabled: "false"
      cluster.remote.connect: "false"
      MAX_LOCKED_MEMORY: unlimited
      bootstrap.memory_lock: "true"
      ES_JAVA_OPTS: "-Xms3g -Xmx3g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    depends_on:
      - es-data-01
      - es-data-02
    configs: *eslimitsConf
    networks: *allinoneNetwork
    extra_hosts: *addhost
    deploy:
      endpoint_mode: dnsrr
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    logging: *allinoneLogging

  es-master-03:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELKVERSION:-7.17.13}
    hostname: es-master-03
    volumes:
      - type: volume
        source: es-master-03
        target: /usr/share/elasticsearch/data
        volume:
          nocopy: true
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      network.host: 0.0.0.0
      cluster.name: es-swarm-cluster
      node.name: "es-master-03"
      discovery.seed_hosts: "es-master-01,es-master-02,es-master-03"
      cluster.initial_master_nodes: "es-master-01,es-master-02,es-master-03"
      node.master: "true"
      node.voting_only: "false"
      node.data: "false"
      node.ingest: "false"
      node.ml: "false"
      xpack.ml.enabled: "false"
      cluster.remote.connect: "false"
      MAX_LOCKED_MEMORY: unlimited
      bootstrap.memory_lock: "true"
      ES_JAVA_OPTS: "-Xms3g -Xmx3g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    depends_on:
      - es-data-01
      - es-data-02
    configs: *eslimitsConf
    networks: *allinoneNetwork
    extra_hosts: *addhost
    deploy:
      endpoint_mode: dnsrr
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    logging: *allinoneLogging

  es-data-01:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELKVERSION:-7.17.13}
    hostname: es-data-01
    volumes:
      - type: volume
        source: es-data-01
        target: /usr/share/elasticsearch/data
        volume:
          nocopy: true
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      network.host: 0.0.0.0
      cluster.name: es-swarm-cluster
      node.name: "es-data-01"
      discovery.seed_hosts: "es-master-01,es-master-02,es-master-03"
      cluster.initial_master_nodes: "es-master-01,es-master-02,es-master-03"
      node.master: "false"
      node.voting_only: "false"
      node.data: "true"
      node.ingest: "false"
      node.ml: "false"
      xpack.ml.enabled: "false"
      cluster.remote.connect: "false"
      MAX_LOCKED_MEMORY: unlimited
      bootstrap.memory_lock: "true"
      ES_JAVA_OPTS: "-Xms3g -Xmx3g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    configs: *eslimitsConf
    networks: *allinoneNetwork
    extra_hosts: *addhost
    deploy:
      endpoint_mode: dnsrr
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    logging: *allinoneLogging

  es-data-02:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELKVERSION:-7.17.13}
    hostname: es-data-02
    volumes:
      - type: volume
        source: es-data-02
        target: /usr/share/elasticsearch/data
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      network.host: 0.0.0.0
      cluster.name: es-swarm-cluster
      node.name: "es-data-02"
      discovery.seed_hosts: "es-master-01,es-master-02,es-master-03"
      cluster.initial_master_nodes: "es-master-01,es-master-02,es-master-03"
      node.master: "false"
      node.voting_only: "false"
      node.data: "true"
      node.ingest: "false"
      node.ml: "false"
      xpack.ml.enabled: "false"
      cluster.remote.connect: "false"
      MAX_LOCKED_MEMORY: unlimited
      bootstrap.memory_lock: "true"
      ES_JAVA_OPTS: "-Xms3g -Xmx3g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    configs: *eslimitsConf
    networks: *allinoneNetwork
    extra_hosts: *addhost
    deploy:
      endpoint_mode: dnsrr
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    logging: *allinoneLogging

  es-ingest:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELKVERSION:-7.17.13}
    hostname: es-ingest
    volumes: &allinoneVolume
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      network.host: 0.0.0.0
      ES_JAVA_OPTS: "-Xms1g -Xmx1g"
      cluster.name: es-swarm-cluster
      discovery.seed_hosts: "es-master-01,es-master-02,es-master-03"
      cluster.initial_master_nodes: "es-master-01,es-master-02,es-master-03"
      node.name: "es-ingest"
      node.master: "false"
      node.voting_only: "false"
      node.data: "false"
      node.ingest: "true"
      node.ml: "false"
      cluster.remote.connect: "false"
      MAX_LOCKED_MEMORY: unlimited
      bootstrap.memory_lock: "true"
      xpack.monitoring.collection.enabled: "false"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    depends_on:
      - es-master-01
      - es-master-02
      - es-master-03
    configs: *eslimitsConf
    networks: *allinoneNetwork
    extra_hosts: *addhost
    deploy:
      endpoint_mode: dnsrr
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    logging: *allinoneLogging

  es-coordinating:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELKVERSION:-7.17.13}
    hostname: es-coordinating
    ports:
      - target: 9200
        published: 9200
        protocol: tcp
        mode: host
    volumes: &allinoneVolume
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      network.host: 0.0.0.0
      ES_JAVA_OPTS: "-Xms1g -Xmx1g"
      cluster.name: es-swarm-cluster
      discovery.seed_hosts: "es-master-01,es-master-02,es-master-03"
      cluster.initial_master_nodes: "es-master-01,es-master-02,es-master-03"
      node.name: "es-coordinating"
      node.master: "false"
      node.voting_only: "false"
      node.data: "false"
      node.ingest: "false"
      node.ml: "false"
      cluster.remote.connect: "false"
      MAX_LOCKED_MEMORY: unlimited
      bootstrap.memory_lock: "true"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    depends_on:
      - es-master-01
      - es-master-02
      - es-master-03
    configs: *eslimitsConf
    networks: *allinoneNetwork
    extra_hosts: *addhost
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    logging: *allinoneLogging

  elastichq:
    image: elastichq/elasticsearch-hq
    environment:
      - HQ_DEFAULT_URL=http://es-coordinating:9200
      - HQ_DEBUG=True
      - HQ_ENABLE_SSL=False
      - HQ_VERIFY_CERTS=False
    volumes: *allinoneVolume
    networks: *allinoneNetwork
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: elastichq

  kibana:
    image: docker.elastic.co/kibana/kibana:${ELKVERSION:-7.17.13}
    hostname: kibana
    volumes:
      - kibana-volume:/usr/share/kibana/config
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      - "ELASTICSEARCH_URL=http://es-coordinating:9200"
      - "ELASTICSEARCH_HOSTS=http://es-coordinating:9200"
    depends_on:
      - es-coordinating
    networks: *allinoneNetwork
    extra_hosts: *addhost
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: kibana

  logstash:
    image: docker.elastic.co/logstash/logstash:${ELKVERSION:-7.17.13}
    ports:
      - "5000:5000"
      - "9600:9600"
      - "5044:5044"
    configs:
      - source: logstash_config
        target: /usr/share/logstash/config/logstash.yml
      - source: logstash_pipeline
        target: /usr/share/logstash/pipeline/logstash.conf
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"
    depends_on:
      - kibana
    volumes: *allinoneVolume
    networks: *allinoneNetwork
    extra_hosts: *addhost
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: logstash

  apm-server:
    image: docker.elastic.co/apm/apm-server:${ELKVERSION:-7.17.13}
    ports:
      - "8200:8200"
    configs:
      - source: apmserver.conf
        target: /usr/share/apm-server/apm-server.yml
    volumes: *allinoneVolume
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: apmserver

  fluentd:
    image: 313.co.kr:5550/313devgrp/fluentd:3.1.5
    configs:
      - source: fluentd.conf
        target: /fluentd/etc/fluent.conf
    volumes: *allinoneVolume
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging: *allinoneLogging

  ######################################### Auth #########################################
  guacd:
    image: guacamole/guacd
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: guacd

  guacamole:
    image: guacamole/guacamole:1.4.0
    depends_on:
      - mysql
    environment:
      GUACD_HOSTNAME: guacd
      MYSQL_HOSTNAME: mysql
      MYSQL_DATABASE: guacamoledb?verifyServerCertificate=false&useSSL=false&requireSSL=false
      MYSQL_USER: mysqluser
      MYSQL_PASSWORD: mysqluserpassword
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: guacamole

  keycloak:
    image: jboss/keycloak:12.0.4
    environment:
      - DB_VENDOR=MYSQL
      - DB_ADDR=mysql
      - DB_DATABASE=keycloakdb
      - DB_USER=mysqluser
      - DB_PASSWORD=mysqluserpassword
      - KEYCLOAK_USER=admin
      - KEYCLOAK_PASSWORD=qwe123
      - JDBC_PARAMS=serverTimezone=UTC&connectTimeout=30000
      #- KEYCLOAK_FRONTEND_URL=http://www.313.co.kr/auth
      #- PROXY_ADDRESS_FORWARDING=true
      #- VIRTUAL_HOST=http://www.313.co.kr
    depends_on:
      - mysql
      - traefik
    volumes:
      - keycloak-volume:/opt/jboss/keycloak/themes
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: keycloak

  phpmyadmin:
    image: 313devgrp/phpmyadmin:5.2.1
    environment:
      - PMA_ARBITRARY=1
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: phpmyadmin


  # create database keycloakdb character set utf8 collate utf8_bin;
  # GRANT ALL PRIVILEGES ON keycloakdb.* TO 'mysqluser'@'%';
  # create database matomo character set utf8 collate utf8_bin;
  # GRANT ALL PRIVILEGES ON matomo.* TO 'mysqluser'@'%';

  # create database gnuboard5 character set utf8 collate utf8_bin;
  # GRANT ALL PRIVILEGES ON gnuboard5.* TO 'mysqluser'@'%';

  # create database aRMS character set utf8 collate utf8_bin;
  # GRANT ALL PRIVILEGES ON aRMS.* TO 'mysqluser'@'%';
  # create database sonarqube character set utf8 collate utf8_bin;
  # GRANT ALL PRIVILEGES ON sonarqube.* TO 'mysqluser'@'%';
  # flush privileges;
  mysql:
    image: mysql:5.7.34
    ports:
      - "3306:3306"
    environment:
      - MYSQL_DATABASE=testdb
      - MYSQL_USER=mysqluser
      - MYSQL_PASSWORD=mysqluserpassword
      - MYSQL_ROOT_PASSWORD=mysqlrootpass
      - TZ=Asia/Seoul
    command: >-
      --user=mysql
      --port=3306
      --pid-file=/data/dbfiles/mysql.pid
      --datadir=/data/dbfiles
      --tmpdir=/data/dbfiles
      --long_query_time=1
      --lc-messages=en_US
      --event_scheduler=1
      --default_password_lifetime=0
      --log_timestamps=SYSTEM
      --explicit_defaults_for_timestamp=on
      --character-set-client-handshake=FALSE
      --character-set-server=utf8mb4
      --collation-server=utf8mb4_unicode_ci
      --skip-external-locking
      --skip-name-resolve
      --transaction-isolation=READ-COMMITTED
      --query_cache_size=0
      --query_cache_limit=0
      --bind-address=0.0.0.0
      --max_connect_errors=9999999
      --max_connections=1024
      --table_open_cache=2048
      --max_allowed_packet=64M
      --performance_schema
      --local_infile=0
      --secure_file_priv=''
      --log_error_verbosity=1
      --tmp_table_size=128M
      --max_heap_table_size=1G
      --server-id=1
      --default-storage-engine=InnoDB
      --thread_cache_size=64
      --binlog_cache_size=1M
      --back_log=1024
      --ft_min_word_len=4
      --read_buffer_size=2M
      --read_rnd_buffer_size=16M
      --sort_buffer_size=2M
      --join_buffer_size=2M
      --skip-external-locking
      --key_buffer_size=128M
      --bulk_insert_buffer_size=64M
      --myisam_sort_buffer_size=128M
      --myisam_max_sort_file_size=512M
      --myisam_repair_threads=1
      --innodb_checksum_algorithm=NONE
      --innodb_buffer_pool_size=32G
      --innodb_file_per_table
      --innodb_data_file_path=ibdata1:1G;ibdata2:1G;ibdata3:1G:autoextend
      --innodb_data_home_dir=/data/dbfiles/
      --innodb_write_io_threads=2
      --innodb_read_io_threads=8
      --innodb_fast_shutdown
      --innodb_autoinc_lock_mode=1
      --innodb_thread_concurrency=4
      --innodb_flush_log_at_trx_commit=1
      --innodb_max_dirty_pages_pct=90
      --innodb_doublewrite=0
      --innodb_lock_wait_timeout=120
      --innodb_open_files=1024
      --innodb_log_buffer_size=16M
      --innodb_log_file_size=256M
      --innodb_log_files_in_group=3
      --innodb_log_group_home_dir=/data/logs/redolog
      --binlog_cache_size=1M
      --log-bin=/data/logs/binlog/mysql-log-bin
      --log_bin_trust_function_creators=1
      --expire_logs_days=7
      --max_binlog_size=100M
      --binlog_format=row
      --binlog_row_image=minimal
      --binlog_checksum=none
      --sync_binlog=1
      --gtid_mode=off
      --enforce_gtid_consistency=off
      --binlog-ignore-db=performance_schema
      --binlog-ignore-db=information_schema
      --binlog-ignore-db=sys
      --log_slave_updates=1
    volumes:
      - mysql-volume:/data
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: mysql

  ######################################### DevTool #########################################

  jira:
    image: 313devgrp/jira:12.14
    volumes:
      - jiraHome:/web/atlassian-jira-5.2.11-standalone/home
      - jiraServer:/web/atlassian-jira-5.2.11-standalone/bin
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: jira

  confluence:
    image: 313devgrp/confluence:12.14
    volumes:
      - confluenceHome:/web/atlassian-confluence-4.3.7/data
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: confluence

  fecru:
    image: 313devgrp/fecru:13.02
    volumes:
      - fecruHome:/web/fecru-3.3.3/var
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: fecru

  sonarqube:
    image: sonarqube:9.9.1-community
    environment:
      #SONAR_WEB_CONTEXT: /sonar - sonarqubeConf 처리
      SONAR_JDBC_URL: jdbc:postgresql://postgres:5432/sonarqube
      SONAR_JDBC_USERNAME: postgresuser
      SONAR_JDBC_PASSWORD: postgresuserpass
    volumes:
      - sonarqubeConf:/opt/sonarqube/conf
      - sonarqubeData:/opt/sonarqube/data
      - sonarqubeExtensions:/opt/sonarqube/extensions
      - sonarqubeLogs:/opt/sonarqube/logs
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: sonarqube

  postgres:
    image: postgres:12.15
    environment:
      POSTGRES_USER: postgresuser
      POSTGRES_PASSWORD: postgresuserpass
      POSTGRES_DB: sonarqube
    volumes:
      - postgrespv:/var/lib/postgresql/data
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: postgres

  pgadmin:
    image: dockage/phppgadmin:latest
    environment:
      - PHP_PG_ADMIN_SERVER_DESC=PostgreSQL
      - PHP_PG_ADMIN_SERVER_HOST=postgres
      - PHP_PG_ADMIN_SERVER_PORT=5432
      - PHP_PG_ADMIN_SERVER_SSL_MODE=allow
      - PHP_PG_ADMIN_SERVER_DEFAULT_DB=template1
      - PHP_PG_ADMIN_SERVER_PG_DUMP_PATH=/usr/bin/pg_dump
      - PHP_PG_ADMIN_SERVER_PG_DUMPALL_PATH=/usr/bin/pg_dumpall
      - PHP_PG_ADMIN_DEFAULT_LANG=auto
      - PHP_PG_ADMIN_AUTO_COMPLETE=default on
      - PHP_PG_ADMIN_EXTRA_LOGIN_SECURITY=false
      - PHP_PG_ADMIN_OWNED_ONLY=false
      - PHP_PG_ADMIN_SHOW_COMMENTS=true
      - PHP_PG_ADMIN_SHOW_ADVANCED=false
      - PHP_PG_ADMIN_SHOW_SYSTEM=false
      - PHP_PG_ADMIN_MIN_PASSWORD_LENGTH=1
      - PHP_PG_ADMIN_LEFT_WIDTH=200
      - PHP_PG_ADMIN_THEME=default
      - PHP_PG_ADMIN_SHOW_OIDS=false
      - PHP_PG_ADMIN_MAX_ROWS=30
      - PHP_PG_ADMIN_MAX_CHARS=50
      - PHP_PG_ADMIN_USE_XHTML_STRICT=false
      - PHP_PG_ADMIN_HELP_BASE=http://www.postgresql.org/docs/%s/interactive/
      - PHP_PG_ADMIN_AJAX_REFRESH=3
      - PHP_PG_ADMIN_URL_PREFIX=/pgadmin
    volumes:
      - pgadmindata:/var/www
      - pgadminconf:/etc/nginx
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: pgadmin

  jenkins:
    image: jenkins/jenkins:2.319.3-lts
    environment:
      JAVA_OPTS: "-Xms1g -Xmx1g -XX:+UseG1GC -Dfile.encoding=UTF-8 -Dhudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION=true"
      JENKINS_OPTS: "--prefix=/jenkins"
    ports:
      - "38080:8080"
      - "50000:50000"
    volumes:
      - jenkinsHome:/var/jenkins_home
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: jenkins

  zipkin:
    image: openzipkin/zipkin:2.23.16
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      - STORAGE_TYPE=elasticsearch
      - ES_HOSTS=es-coordinating:9200
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    networks: *allinoneNetwork
    healthcheck:
      disable: true
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: zipkin

  zipkinDependencies:
    image: openzipkin/zipkin-dependencies:2.6.4
    entrypoint: crond -f
    environment:
      - STORAGE_TYPE=elasticsearch
      - "ES_HOSTS=es-coordinating:9200"
      - "ES_NODES_WAN_ONLY=true"
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: zipkinDependencies

  jrebel:
    image: 313devgrp/jrebel:2018.07.12
    ports:
      - "31301:8888"
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: jrebel

  nexus:
    image: sonatype/nexus3:3.62.0
    ports:
      - "8081:8081"
      - "5550:5550"
      - "5551:5551"
    environment:
      - NEXUS_CONTEXT=nexus
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
      - nexus-volume:/nexus-data
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: nexus

  ######################################### Spinnaker #########################################

  halyard:
    image: us-docker.pkg.dev/spinnaker-community/docker/halyard:0.41.0
    ports:
      - 8064:8064
    volumes:
      - halyardVolume:/home/spinnaker/.hal
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    depends_on: &spinnaker-depend
      - redis
      - minio
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: halyard

  clouddriver:
    image: us-docker.pkg.dev/spinnaker-community/docker/clouddriver:2.0.0-20180221152902
    ports:
      - 7002:7002
    volumes: &configSpinnakerVolume
      - config-spinnaker-volume:/opt/spinnaker/config
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    depends_on: *spinnaker-depend
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: clouddriver

  deck:
    image: us-docker.pkg.dev/spinnaker-community/docker/deck:2.1.0-20180221143146
    ports:
      - 9000:9000
    #    extra_hosts: *addHost
    volumes:
      - config-spinnaker-volume:/opt/spinnaker/config
      - deck-html-volume:/opt/deck/html
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    depends_on: *spinnaker-depend
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: deck

  igor:
    image: us-docker.pkg.dev/spinnaker-community/docker/igor:0.9.0-20180221133510
    ports:
      - 8088:8088
    volumes: *configSpinnakerVolume
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    depends_on: *spinnaker-depend
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: igor

  front50:
    image: us-docker.pkg.dev/spinnaker-community/docker/front50:0.9.0-20180221133510
    ports:
      - 8080:8080
    environment:
      AWS_ACCESS_KEY_ID: "minio"
      AWS_SECRET_KEY: "miniostorage"
    volumes: *configSpinnakerVolume
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    depends_on: *spinnaker-depend
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: front50

  echo:
    image: us-docker.pkg.dev/spinnaker-community/docker/echo:0.8.0-20180221133510
    ports:
      - 8089:8089
    volumes: *configSpinnakerVolume
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    depends_on: *spinnaker-depend
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: echo

  orca:
    image: us-docker.pkg.dev/spinnaker-community/docker/orca:0.10.0-20180221133510
    ports:
      - 8083:8083
    volumes: *configSpinnakerVolume
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    depends_on: *spinnaker-depend
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: orca

  rosco:
    image: us-docker.pkg.dev/spinnaker-community/docker/rosco:0.5.0-20180221133510
    ports:
      - 8087:8087
    volumes: *configSpinnakerVolume
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    depends_on: *spinnaker-depend
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: rosco

  fiat:
    image: us-docker.pkg.dev/spinnaker-community/docker/fiat:0.5.0-20180221133510
    ports:
      - 7003:7003
    volumes: *configSpinnakerVolume
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    depends_on: *spinnaker-depend
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: fiat
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --tries=1 --spider http://127.0.0.1:7003/health || exit 1"
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 5m

  gate:
    image: us-docker.pkg.dev/spinnaker-community/docker/gate:0.10.0-20180221133510
    ports:
      - 8084:8084
    volumes: *configSpinnakerVolume
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    depends_on: *spinnaker-depend
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: gate

    #end of life
    #  monitoring-daemon:
    #    image: us-docker.pkg.dev/spinnaker-community/docker/monitoring-daemon:0.5.0-20180221133510
    #    ports:
    #      - 8228:8008
    #    healthcheck:
    #      disable: true
    #extra_hosts: *addHost
  #    deploy:
  #      mode: replicated
  #      replicas: 1
  #      placement:
  #        constraints: [node.hostname == k8s3]
  #    depends_on: *spinnaker-depend
  #    networks: *allinoneNetwork
  #    logging:
  #      driver: fluentd
  #      options:
  #        fluentd-address: fluentd:24224
  #        fluentd-async-connect: "true"
  ##        fluentd-retry-wait: "300s"
  ##        fluentd-max-retries: "30"
  #        tag: monitoringDaemon

  redis:
    image: redis:4.0.13
    command: redis-server /usr/local/etc/redis/6379.conf --port 6379 --appendonly yes
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
      - redis-conf:/usr/local/etc/redis
      - redis-data:/data
    ports:
      - 6379:6379
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: redis

  redis-commander:
    image: rediscommander/redis-commander:latest
    environment:
      - REDIS_HOSTS=local:redis:6379
    volumes:
      - rediscommander:/redis-commander
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    depends_on: *spinnaker-depend
    healthcheck:
      disable: true
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: rediscommander

  minio:
    image: minio/minio:RELEASE.2019-12-30T05-45-39Z
    command: server --config-dir /etc/minio --address ":62222" /data
    environment:
      - MINIO_ROOT_USER=minio
      - MINIO_ROOT_PASSWORD=miniostorage
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=miniostorage
      - MINIO_REGION=us-east-1
    volumes:
      - minio-config-volume:/etc/minio
      - minio-data-volume:/data
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    ports:
      - 62222:62222
    healthcheck:
      disable: true
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s2]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: minio


  middle-proxy:
    image: 313.co.kr:5550/313devgrp/java-service-tree-framework-middle-proxy:3.13.3
    ports:
      - 13131:13131
    volumes:
      - middle-proxy-volume:/mnt
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s1]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: middleproxy

  backend-core:
    image: 313.co.kr:5550/313devgrp/java-service-tree-framework-backend-core:3.13.3
    ports:
      - 31313:31313
    volumes:
      - backend-core-volume:/mnt
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: backendcore

  engine-fire:
    image: 313.co.kr:5550/313devgrp/java-service-tree-framework-engine-fire:3.13.3
    ports:
      - 33333:33333 ##직접 호출 케이스 : 배치 작업
    volumes:
      - engine-fire-volume:/mnt
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.hostname == k8s3]
    networks: *allinoneNetwork
    extra_hosts: *addhost
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: enginefire


configs:
  fluentd.conf:
    file: ./config/fluent.conf
  apmserver.conf:
    file: ./config/apm-server.yml
  es-limits.conf:
    file: ./config/es-limits.conf
  logstash_config:
    file: ./config/logstash.yml
  logstash_pipeline:
    file: ./config/logstash.conf

volumes:

  ######################################### Global Service #########################################
  portainer-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/portainer/data"

  nginx-www:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":/volume1/web"

  nginx-conf:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/nginx"

  apachephp-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/apachephp"

  grafana-data:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/grafana/data"

  grafana-etc:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/grafana/etc"

  prometheus-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/prometheus/data"

  ######################################### ELFK #########################################
  kibana-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/kibana/conf"

  es-master-01:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/es-master-01"

  es-master-02:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/es-master-02"

  es-master-03:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/es-master-03"

  es-data-01:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/es-data-01"

  es-data-02:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/es-data-02"

  ######################################### Auth #########################################

  keycloak-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/keycloak"

  mysql-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/mysql"

  ######################################### DevTool #########################################

  pgadminconf:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/pgadmin/conf"

  pgadmindata:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/pgadmin/data"

  postgrespv:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/postgres"

  sonarqubeConf:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/sonarqube/conf"

  sonarqubeData:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/sonarqube/data"

  sonarqubeExtensions:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/sonarqube/extensions"

  sonarqubeLogs:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/sonarqube/logs"

  nexus-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/nexus"

  jenkinsHome:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/jenkins"

  jiraHome:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/jira/home"

  jiraServer:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/jira/server"

  confluenceHome:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/confluence"

  fecruHome:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/fecru"

  sonarHome:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/sonar"

  ######################################### Spinnaker #########################################

  rediscommander:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/redis-commander"

  halyardVolume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/spinnaker/halyard"

  redis-conf:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/redis/redis-conf"

  redis-data:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/redis/redis-data"

  config-spinnaker-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/spinnaker/config"

  deck-html-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/spinnaker/deck-html"

  minio-config-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/minio/config"

  minio-data-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/minio/data"

  ######################################### Application #########################################

  middle-proxy-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/app/middle-proxy"

  backend-core-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/app/backend-core"

  engine-fire-volume:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=${NFSSERVER:-1.2.3.4},nolock,soft,rw,sync"
      device: ":${NFSPATH:-/nfspath}/allinone/app/engine-fire"


networks:
  allinoneNetwork:
    driver: overlay
    attachable: true